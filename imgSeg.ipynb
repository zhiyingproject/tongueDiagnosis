{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imgSeg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhiyingproject/tongueDiagnosis/blob/main/imgSeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECDyxU8NSj1l"
      },
      "source": [
        "# This notebook is to train a model for locating tongues from people's faces. It is for tongue diagnosis using traditional Chinese Medical Theory (TCM)\n",
        "!pip uninstall keras-nightly\n",
        "!pip install h5py==2.10.0\n",
        "!pip install --upgrade tensorflow==1.15.0\n",
        "!pip install --upgrade tensorflow-gpu==1.15\n",
        "# !pip install --upgrade keras==2.2.4\n",
        "!python -m pip install -U scikit-image==0.16.2\n",
        "# !pip uninstall keras \n",
        "!pip install keras==2.2.4\n",
        "!pip install wcmatch\n",
        "# %tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YQgfikcgWuLW",
        "outputId": "f2b50f03-e7ff-4a09-8834-29c55f0d71ae"
      },
      "source": [
        "# Restarting the kernel to enable tensorflow v1.14\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<script>Jupyter.notebook.kernel.restart()</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tlG8iofWvg7"
      },
      "source": [
        "# Install Mask RCNN\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIMB9aLXW2jk",
        "outputId": "68ce5c3f-7b20-4c25-fed9-4084daf5f44e"
      },
      "source": [
        "cd Mask_RCNN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-eVzAQ8W6LG"
      },
      "source": [
        "# Setup libraries for Mas RCNN\n",
        "!python setup.py install\n",
        "!pip show mask-rcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAIIagFGXrnJ",
        "outputId": "ef7872b4-4a67-439b-dd8a-f9581507b378"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWmN6kDRZN3M",
        "outputId": "5709c423-52cc-4155-c52d-1063411ab92e"
      },
      "source": [
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import sys\n",
        "from mrcnn.utils import Dataset, extract_bboxes, compute_ap\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.visualize import display_instances\n",
        "from numpy import zeros, asarray\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
        "from numpy import zeros, asarray, expand_dims, mean\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja0fZ4TUYRq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73abe857-f4db-4b10-fc24-6b9db5c1405b"
      },
      "source": [
        "\n",
        "from wcmatch.pathlib import Path\n",
        "ds_path = '/content/drive/MyDrive/backup/tongueDiagnosis/segTraining'\n",
        "num_files = len(list(Path(ds_path).rglob(['*.jpg', '*.JPG', '*.jpeg'])))\n",
        "training_threshold = int(num_files * 0.9)\n",
        "print(training_threshold, num_files - training_threshold)\n",
        "model_path = '/content/drive/MyDrive/backup/tongueDiagnosis/models'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "485 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_omxXKCBZHOp"
      },
      "source": [
        "class tongueDataset(Dataset):\n",
        "    def load_dataset(self, dataset_dir, is_train=True):\n",
        "        self.add_class(\"dataset\", 1, \"tongue\")\n",
        "\n",
        "        images_dir = dataset_dir\n",
        "        annotations_dir = f'{dataset_dir}/annots'\n",
        "        image_files = Path(dataset_dir).rglob(['*.jpg','*.JPG','*.jpeg'])\n",
        "        for ifile, filename in enumerate(list(image_files)):\n",
        "            image_id = filename.stem\n",
        "            if is_train and ifile >= training_threshold:\n",
        "                continue\n",
        "            if not is_train and ifile < training_threshold:\n",
        "                continue\n",
        "            img_path = filename\n",
        "            ann_path = f'{annotations_dir}/{filename.stem}.xml'\n",
        "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "    def extract_boxes(self, filename):\n",
        "        tree = ET.parse(filename)\n",
        "        root = tree.getroot()\n",
        "        boxes = list()\n",
        "        for box in root.findall('.//bndbox'):\n",
        "            xmin = int(box.find('xmin').text)\n",
        "            ymin = int(box.find('ymin').text)\n",
        "            xmax = int(box.find('xmax').text)\n",
        "            ymax = int(box.find('ymax').text)\n",
        "            coors = [xmin, ymin, xmax, ymax]\n",
        "            boxes.append(coors)\n",
        "        width = int(root.find('.//size/width').text)\n",
        "        height = int(root.find('.//size/height').text)\n",
        "        return boxes, width, height\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        path = info['annotation']\n",
        "        boxes, w, h = self.extract_boxes(path)\n",
        "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "        class_ids = []\n",
        "        for i in range(len(boxes)):\n",
        "            box = boxes[i]\n",
        "            row_s, row_e = box[1], box[3]\n",
        "            col_s, col_e = box[0], box[2]\n",
        "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
        "            class_ids.append(self.class_names.index('tongue'))\n",
        "        return masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqdCwjghZbaZ"
      },
      "source": [
        "class tongueConfig(Config):\n",
        "    NAME = 'tongue_cfg'\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    STEPS_PER_EPOCH = training_threshold\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFx1QEARZpBi",
        "outputId": "bedfa473-9c2d-4dae-e935-6325394f1d9a"
      },
      "source": [
        "training_ds = tongueDataset()\n",
        "training_ds.load_dataset(ds_path, is_train=True)\n",
        "training_ds.prepare()\n",
        "print('Train: %d' % len(training_ds.image_ids))\n",
        "\n",
        "test_ds = tongueDataset()\n",
        "test_ds.load_dataset(ds_path, is_train=False)\n",
        "test_ds.prepare()\n",
        "print('Test: %d' % len(test_ds.image_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 485\n",
            "Test: 54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsq59vwvZwTJ"
      },
      "source": [
        "config = tongueConfig()\n",
        "config.display()\n",
        "\n",
        "model = MaskRCNN(mode='training', model_dir=model_path, config=config)\n",
        "model.load_weights('/content/drive/MyDrive/backup/tongueDiagnosis/models/mask_rcnn_coco.h5', \n",
        "                   by_name=True,\n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "model.train(training_ds, test_ds, learning_rate=config.LEARNING_RATE, epochs=16, layers='heads')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi9LMjVubRqq"
      },
      "source": [
        "class predictionConfig(Config):\n",
        "    NAME = 'tongue_cfg'\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtFexi1UbTtt"
      },
      "source": [
        "def evaluate_model(ds, model, cfg):\n",
        "    APs = list()\n",
        "    for i, img_id in enumerate(ds.image_ids):\n",
        "        print(ds.image_info[i])\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(ds, cfg, img_id, use_mini_mask=False)\n",
        "        scaled_image = mold_image(image, cfg)\n",
        "        sample = expand_dims(scaled_image, 0)\n",
        "        yhat = model.detect(sample, verbose=0)\n",
        "        r = yhat[0]\n",
        "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r['rois'], r['class_ids'], r['scores'], r['masks'],0.65)\n",
        "        print(AP)\n",
        "        if math.isnan(AP):\n",
        "            continue\n",
        "        APs.append(AP)\n",
        "    mAP = mean(APs)\n",
        "    return mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKhbt11ebz-C"
      },
      "source": [
        "\n",
        "training_ds = tongueDataset()\n",
        "training_ds.load_dataset(ds_path, is_train=True)\n",
        "training_ds.prepare()\n",
        "print('Train: %d' % len(training_ds.image_ids))\n",
        "\n",
        "test_ds = tongueDataset()\n",
        "test_ds.load_dataset(ds_path, is_train=False)\n",
        "test_ds.prepare()\n",
        "print('Test: %d' % len(test_ds.image_ids))\n",
        "\n",
        "\n",
        "weights_file = '/content/drive/MyDrive/backup/tongueDiagnosis/models/mask_rcnn_tongue_cfg_0016.h5'  # !!!!!need to identify\n",
        "print(model_path)\n",
        "cfg_pred = predictionConfig()\n",
        "model = MaskRCNN(mode='inference', model_dir=model_path, config=cfg_pred)\n",
        "model.load_weights(weights_file, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP4ZPDMycUW-"
      },
      "source": [
        "train_mAP = evaluate_model(test_ds, model, cfg_pred)\n",
        "print(\"Test mAP: %.3f\" % train_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL86eAOyfEVV"
      },
      "source": [
        "def plot_actual_vs_predicted(ds, model, cfg, start, end):\n",
        "    i = 0\n",
        "    for i_img in range(start, end):\n",
        "        image = ds.load_image(i_img)\n",
        "        n_image = end - start + 1\n",
        "        print(ds.image_info[i_img]['id'])\n",
        "        mask, _ = ds.load_mask(i_img)\n",
        "        scaled_image = mold_image(image, cfg)\n",
        "        sample = expand_dims(scaled_image, 0)\n",
        "        yhat = model.detect(sample, verbose=0)[0]\n",
        "        plt.subplot(n_image, 2, i*2+1)\n",
        "        plt.imshow(image)\n",
        "        # plt.title('Actual')\n",
        "        for j in range(mask.shape[2]):\n",
        "            plt.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "        plt.subplot(n_image, 2, i*2+2)\n",
        "        plt.imshow(image)\n",
        "        # plt.title('Predict')\n",
        "        ax = plt.gca()\n",
        "        for box in yhat['rois']:\n",
        "            y1, x1, y2, x2 = box\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "            ax.add_patch(rect)\n",
        "        i += 1\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL3n1imGfT-4"
      },
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "plot_actual_vs_predicted(test_ds, model, cfg_pred, 5,10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}